#Attempt to Get Revenue in R
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("did")
install.packages("tidyverse")
install.packages("lmtest")
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
Census State and Local Data- Tax Foundation
# Census State and Local Data- Tax Foundation
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("xlsx")
library(readxl)
library(tidyr)
library(dplyr)
library(tidyverse)
library(xlsx)
#Nebraska or "Direct Switchers DiD Approach"
#Run DiD with all the Direct Switchers (NE, MO, MS, CO, RI, ND, DE)
#Control Group is all States that Did not Switch by 2007.
#this includes: AK, HI, KS, NM, OK.  AL and MT between 2008-now became "Step
#-wise" switchers.  FL and MA had DWS over the whole period 1976-2022.
library(tidyr)
library(dplyr)
library(tidyverse)
# for robust standard error estimation
library(lmtest)
# To calculate correct vcov matrix with 2WFE
library(multiwayvcov)
# For a package way to do FE
library(plm)
#Fixest
install.packages("fixest")
library(fixest)
#Load Data Tables in R
install.packages("data.table")
# Get rate of change for tax bases and find elasticity of tax base w.r.t apportionment and rate changes.
#Redo Callaway and Sant'Anna From Summer
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
library(caret)
library(ggplot2)
#New Directory
setwd("~/Documents/GitHub/ST_Apportionment/Rates_Of_Change")
#Load Packages
library(tidyr)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(broom) #extract coefficients for each state
#set directory
setwd("~/Documents/GitHub/ST-Apportionment/job_market_data")
#Load Data, Coefficient Plot & Rev Data for estimates
Coef <-read.csv("state_post_dummy_total_rev._6_15_24.csv")
Rev <-read.csv("revenue_panel_total_rev_state_coef_result_6_15_24.csv")
Rev <-Rev %>%
select(-X)
Coef <-Coef %>%
select(-X)
View(Coef)
View(Rev)
View(Rev)
if (!require(car)) install.packages("car")
library(car)
# Fit the interaction regression model again (if not already done)
interaction_model <- lm(log_totrev ~ Post * factor(State_Name) + factor(year), data = Rev)
# Get the names of all the Post:factor(State_Name) coefficients
interaction_terms <- grep("Post:factor\\(State_Name\\)", names(coef(interaction_model)), value = TRUE)
# Formulate the hypothesis for the linearHypothesis function
hypothesis <- paste(interaction_terms, "= 0")
# Perform the joint hypothesis test
test_result <- linearHypothesis(interaction_model, hypothesis)
aliased <- alias(interaction_model)
View(aliased)
print(aliased)
# Set up sum contrasts for the State_Name factor
contrasts(Rev$State_Name) <- contr.sum(length(unique(Rev$State_Name)))
# Convert State_Name to a factor
Rev$State_Name <- factor(Rev$State_Name)
# Set up sum contrasts for the State_Name factor
contrasts(Rev$State_Name) <- contr.sum(length(unique(Rev$State_Name)))
# Set up sum contrasts for the State_Name factor
num_states <- length(unique(Rev$State_Name))
contrasts(Rev$State_Name) <- contr.sum(num_states)
# Fit the interaction regression model including the main effect of State_Name
interaction_model <- lm(log_totrev ~ Post * factor(State_Name) + factor(year), data = Rev)
summary(interaction_model)
# Get the names of all the Post:factor(State_Name) coefficients
interaction_terms <- grep("Post:factor\\(State_Name\\)", names(coef(interaction_model)), value = TRUE)
# Formulate the hypothesis for the linearHypothesis function
# We test the hypothesis that all Post:factor(State_Name) coefficients are zero
hypothesis <- paste(interaction_terms, "= 0")
# Perform the joint hypothesis test
test_result <- linearHypothesis(interaction_model, hypothesis)
# Check for aliased coefficients
aliased <- alias(interaction_model)
print(aliased)
View(aliased)
# Fit the interaction regression model
interaction_model <- lm(log_totrev ~ Post * State_Name + factor(year), data = Rev)
# Extract coefficients and their standard errors
coefficients <- coef(summary(interaction_model))[, "Estimate"]
std_errors <- coef(summary(interaction_model))[, "Std. Error"]
# Extract coefficients for Post:State_Name interactions
interaction_terms <- grep("Post:State_Name", names(coefficients), value = TRUE)
interaction_coef <- coefficients[interaction_terms]
interaction_se <- std_errors[interaction_terms]
# Formulate the joint hypothesis that no state's effect (Post:State_Name) is different from zero
# H0: beta1 = beta2 = ... = betaN = 0, where beta1, beta2, ..., betaN are coefficients of Post:State_Name interactions
hypothesis <- paste(interaction_terms, "= 0")
# Perform the joint significance test using the F-test
joint_test <- linearHypothesis(interaction_model, hypothesis)
# Print the joint test results
print(joint_test)
summary(interaction_model)
hypothesis <- paste(grep("Post:State_Name", colnames(coef(interaction_model))), "= 0")
joint_test <- linearHypothesis(interaction_model, hypothesis)
# Assume interaction_model is defined previously
interaction_model <- lm(log_totrev ~ Post * State_Name + factor(year), data = Rev)
# Split data by State_Name and fit separate models
state_models <- Rev %>%
group_by(State_Name) %>%
do(model = lm(log_totrev ~ Post + factor(year), data = .))
str(Rev)
# Split data by State_Name and fit separate models
state_models <- Rev %>%
group_by(State_Name) %>%
do(model = lm(log_totrev ~ Post + factor(year), data = .))
# set seed
set.seed(26)
View(Coef)
print(Coef)
# Extract the state names
state_names <- levels(factor(Rev$State_Name))
# Formulate the hypotheses
hypothesis <- paste("Post:factor(State_Name)", state_names, " = 0", sep = "")
hypothesis <- hypothesis[!grepl("Post:factor\\(State_Name\\)Alabama = 0", hypothesis)]  # Exclude reference category if Alabama is the reference
# Perform the F-test
joint_test <- linearHypothesis(interaction_model, hypothesis)
# Fit the unrestricted model (with interactions)
interaction_model <- lm(log_totrev ~ Post * factor(State_Name) + factor(year), data = Rev)
# Fit the restricted model (no Post_Estimates)
restricted_model <- lm(log_totrev ~ factor(State_Name) + factor(year), data = Rev)
# Compute RSS for both models
RSS_unrestricted <- sum(residuals(interaction_model)^2)
RSS_restricted <- sum(residuals(restricted_model)^2)
# Degrees of freedom
df_unrestricted <- df.residual(interaction_model)
df_restricted <- df.residual(restricted_model)
num_restrictions <- df_restricted - df_unrestricted
# Calculate F-statistic
F_statistic <- ((RSS_restricted - RSS_unrestricted) / num_restrictions) / (RSS_unrestricted / df_unrestricted)
# Calculate p-value
p_value <- pf(F_statistic, num_restrictions, df_unrestricted, lower.tail = FALSE)
# Print the results
cat("F-statistic:", F_statistic, "\n")
cat("p-value:", p_value, "\n")
# Determine significance
if (p_value < 0.05) {
cat("The null hypothesis that no state's Post_Estimate is different from zero is rejected.\n")
} else {
cat("The null hypothesis that no state's Post_Estimate is different from zero is not rejected.\n")
}
# Extract individual p-values from the coefficients table
individual_p_values <- Coef$Post_P_Value
names(individual_p_values) <- Coef$State
# Remove NA values (for states that did not have estimates)
individual_p_values <- na.omit(individual_p_values)
# Apply Benjamini-Hochberg procedure to adjust p-values
adjusted_p_values <- p.adjust(individual_p_values, method = "BH")
# Set significance level
alpha <- 0.05
# Determine which states reject the null hypothesis
rejected_states <- names(adjusted_p_values[adjusted_p_values < alpha])
# Print the results
cat("States rejecting the null hypothesis that Post_Estimate is zero:\n")
print(rejected_states)
# Initialize an empty dataframe to store results
results_df <- data.frame(State = character(),
F_statistic = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop through each state and fit models
for (state in unique(Rev$State_Name)) {
# Filter data for the current state
state_data <- subset(Rev, State_Name == state)
# Fit the unrestricted model (with Post)
unrestricted_model <- lm(log_totrev ~ Post + factor(year), data = state_data)
# Fit the restricted model (without Post)
restricted_model <- lm(log_totrev ~ factor(year), data = state_data)
# Compute RSS for both models
RSS_unrestricted <- sum(residuals(unrestricted_model)^2)
RSS_restricted <- sum(residuals(restricted_model)^2)
# Degrees of freedom
df_unrestricted <- df.residual(unrestricted_model)
df_restricted <- df.residual(restricted_model)
num_restrictions <- df_restricted - df_unrestricted
# Calculate F-statistic
F_statistic <- ((RSS_restricted - RSS_unrestricted) / num_restrictions) / (RSS_unrestricted / df_unrestricted)
# Calculate p-value
p_value <- pf(F_statistic, num_restrictions, df_unrestricted, lower.tail = FALSE)
# Append results to the dataframe
results_df <- rbind(results_df, data.frame(State = state,
F_statistic = F_statistic,
p_value = p_value))
}
# Print the results dataframe
print(results_df)
# Determine significance for each state
results_df$Significant <- ifelse(results_df$p_value < 0.05, "Yes", "No")
# Print results with significance
print(results_df)
results_df <- data.frame(
RSS_unrestricted = RSS_unrestricted,
RSS_restricted = RSS_restricted,
df_unrestricted = df_unrestricted,
df_restricted = df_restricted,
F_statistic = F_statistic,
p_value = p_value
)
# Print the results dataframe
print(results_df)
View(Coef)
library(readxl)
#Load Region Dataframe for plot. Also, could use year of switch, trying to find a pattern
Region <- read_xlsx("RNChart.xlsx")
StateNum <- read_xlsx("RegionNumber.xlsx")
View(StateNum)
#Merge Coef and StateNum
Merge <- Coef %>%
full_join(StateNum, by= c("State"))
#Merge Coef and StateNum
Merge <- Coef %>%
full_join(StateNum, by= c("state"))
#Merge Coef and StateNum
Merge <- Coef %>%
full_join(StateNum, by= c("State"="state"))
View(Region)
View(Merge)
#Merge Merge and Number for Region
Merge2 <- Merge %>%
full_join(Region, by = c("Number"))
View(Merge2)
ggplot(Merge2, aes(Post_Estimate)) +
geom_histogram(bins=10)
#Create a scatter plot
ggplot(Merge2,x=Post_Estimate) +
geom_point()
#Create a scatter plot
ggplot(Merge2,aes(x=Post_Estimate) +
geom_point()
ggplot(Merge2, aes(x=Post_Estimate)) +
#density plot of the coefficients
ggplot(Merge2, aes(x = Post_Estimate)) +
geom_density()
#Create a scatter plot
ggplot(Merge2,aes(x=Post_Estimate,y=Number) +
geom_point()
ggplot(Merge2,aes(x=Post_Estimate,y=Number)) +
ggplot(Merge2, aes(x = Post_Estimate, y = Number)) +
geom_point()
#Create a scatter plot
ggplot(Merge2, aes(x = Number, y = Post_Estimate)) +
geom_point()
#Create a scatter plot
ggplot(Merge2, aes(x = Post_Estimate, y = Number, color = Region)) +
geom_point()
View(interaction_model)
View(Rev)
View(Rev)
Switch <- Rev %>%
select(State_Name,year_effective)
#Merge plot df to year
plotdf <- Merge2 %>%
full_join(Switch,by=c("State"="State_Name"))
ggplot(plotdf, aes(x=year_effective,y=Post_Estimate, color = Region)) +
geom_point()
#Try scatter plot again with year on y axis
ggplot(plotdf, aes(x=year_effective,y=Post_Estimate, color = Region)) +
geom_point() + ggtitle("Estimate of SSFA and Year Enacted")
#density plot of the coefficients
ggplot(Merge2, aes(x = Post_Estimate)) +
geom_density() + ggtitle("Density Plot of SSFA Coefficent")
