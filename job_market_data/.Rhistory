#Attempt to Get Revenue in R
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("did")
install.packages("tidyverse")
install.packages("lmtest")
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
Census State and Local Data- Tax Foundation
# Census State and Local Data- Tax Foundation
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("xlsx")
library(readxl)
library(tidyr)
library(dplyr)
library(tidyverse)
library(xlsx)
#Nebraska or "Direct Switchers DiD Approach"
#Run DiD with all the Direct Switchers (NE, MO, MS, CO, RI, ND, DE)
#Control Group is all States that Did not Switch by 2007.
#this includes: AK, HI, KS, NM, OK.  AL and MT between 2008-now became "Step
#-wise" switchers.  FL and MA had DWS over the whole period 1976-2022.
library(tidyr)
library(dplyr)
library(tidyverse)
# for robust standard error estimation
library(lmtest)
# To calculate correct vcov matrix with 2WFE
library(multiwayvcov)
# For a package way to do FE
library(plm)
#Fixest
install.packages("fixest")
library(fixest)
#Load Data Tables in R
install.packages("data.table")
# Get rate of change for tax bases and find elasticity of tax base w.r.t apportionment and rate changes.
#Redo Callaway and Sant'Anna From Summer
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
library(caret)
library(ggplot2)
#New Directory
setwd("~/Documents/GitHub/ST_Apportionment/Rates_Of_Change")
library(tidyr)
library(dplyr)
library(tidyverse)
library(lmtest)
library(ggplot2)
library(did) # for running DiD
library(plm)
library(lmtest)
library(synthdid)
library(fixest)
library(boot)
library(ggthemes)
# set seed
set.seed(26)
#JMP Directory
setwd("~/Documents/GitHub/ST-Apportionment/job_market_data")
naive_ci<-read.csv("naive_ci.csv")
# Next thing to estimate, Real Corporate Income, base year 1983-1984
real_CI <- naive_ci%>%
mutate(real_ci = (naive_ci/CPI_def)*100)
#Make percentage change column for Naive, RealCORPORATE INCOME
per_chan_real_ci <- real_CI %>%
group_by(state)%>%
arrange(state,year)%>%
mutate(per_chan_rci = ((real_ci-lag(real_ci))/((real_ci+lag(real_ci))/2)))%>%
ungroup()
View(per_chan_real_ci)
#Make percentage change column for Naive, RealCORPORATE INCOME
per_chan_real_ci <- real_CI %>%
group_by(state)%>%
arrange(year)%>%
mutate(per_chan_rci = ((real_ci-lag(real_ci))/((real_ci+lag(real_ci))/2)))%>%
ungroup()
View(per_chan_real_ci)
per_chan_real_ci <- real_CI %>%
group_by(state)%>%
arrange(year)%>%
mutate(per_chan_rci = ((real_ci-lag(real_ci))/((real_ci+lag(real_ci))/2))*100)%>%
ungroup()
View(per_chan_real_ci)
per_chan_real_ci2 <- real_CI %>%
group_by(State_Acronym) %>%   # Group by state
arrange(State_Acronym, year) %>%   # Arrange data by state and year
mutate(
lag_real_ci = lag(real_ci),  # Create lagged real_ci
midpoint = (real_ci + lag_real_ci) / 2,  # Compute the midpoint
per_chan_rci = ifelse(
!is.na(lag_real_ci) & midpoint != 0,  # Check for NA and non-zero midpoint
((real_ci - lag_real_ci) / midpoint) * 100,  # Calculate percentage change
NA  # Return NA if the condition is not met
)
) %>%
select(State_Acronym, year, real_ci, lag_real_ci, midpoint, per_chan_rci) %>%   # Select relevant columns
ungroup()
View(per_chan_real_ci2)
# Create a function to calculate percentage change
calculate_percentage_change <- function(df) {
# Initialize vectors to store the previous value and the percentage change
previous_real_ci <- rep(NA, nrow(df))
per_chan_rci <- rep(NA, nrow(df))
# Loop through each group
for (i in seq_len(nrow(df))) {
if (i > 1) {
previous_real_ci[i] <- df$real_ci[i - 1]
midpoint <- (df$real_ci[i] + previous_real_ci[i]) / 2
per_chan_rci[i] <- ((df$real_ci[i] - previous_real_ci[i]) / midpoint) * 100
}
}
df$lag_real_ci <- previous_real_ci
df$per_chan_rci <- per_chan_rci
return(df)
}
# Apply the function to each state group
per_chan_real_ci <- real_CI %>%
group_by(State_Acronym) %>%
arrange(State_Acronym, year) %>%
do(calculate_percentage_change(.)) %>%
ungroup()
# Print the result to verify
print(head(per_chan_real_ci, 20))
View(per_chan_real_ci)
Filter_frac <-per_chan_real_ci %>%
select(State_Acronym,year,year_effective,State_Name,per_chan_rci,Post)
filt_Corp <-Filter_frac
#Create State Dataframes
#create result list to store dataframe
result_list <- list()
# Make a copy of the original dataframe to work with
original_df <- filt_Corp
#counter variable, so as loop progresses, drops first state
counter <- 1
while (TRUE) {
#Reset to original each start
df <-filt_Corp
# Arrange by year_effective and select the first state for treatment
df <- df %>% arrange(year_effective)
#counter variable for running the loop
if(df$year_effective[counter] >= 2022) {break}
treatment_state <- df %>% slice(counter)
treatment_year <- treatment_state$year_effective
treatment_state_name <- treatment_state$State_Name
#filter out prior treated states, but keep no treatment states
#first half of filter keeps no treatment states in,
df <- df %>%
filter(is.na(year_effective) | is.na(State_Acronym) | year_effective >= treatment_year)
# removes states treated in same year
#the year_effective=treatment_year are filtered out if they are not 'treatment_state'
df <- df %>%
filter(is.na(year_effective) | (!(State_Name != treatment_state_name & year_effective == treatment_year)))
# Filter out rows with year <= 2 years after treatment_year
df <- df %>%
filter(year <= treatment_year + 2)
#filter out any states that get treated within 2 years of treatment
df <- df %>%
filter(is.na(year_effective) | (!(year_effective > treatment_year & year_effective<= treatment_year + 2)))
#filter out Ohio after treatment_year >=2012, because OH eliminates CI in 2014
df <- df %>%
filter(!(treatment_year >= 2012 & State_Name == "Ohio"))
# Store the dataframe for this treatment state
assign(treatment_state_name, df)
result_list[[treatment_state_name]] <- df
# Check if the treatment year is 2022 or greater, break
if (treatment_year >= 2022) {break}
#increment counter
counter <-counter + 1
#empty dataframe break
if (nrow(df) == 0) {break}
}
# Initialize an empty list to store point estimates and statistics
point_estimate_list <- list()
# Loop over each dataframe in result_list
for (state_name in names(result_list)) {
# Access the dataframe
current_df <- result_list[[state_name]]
#Make the tibble from the result list a dataframe, easier for panel.matrics function
current_df <- as.data.frame(current_df)
current_year <- current_df$year_effective[1]
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
# Filter out those states from the dataframe
current_df <- current_df %>%
filter(!State_Acronym %in% states_with_inf)
# Create the panel matrices for sDiD using synthdid
current_sDiD <- panel.matrices(current_df, unit = "State_Acronym", time = "year", outcome = "per_chan_rci", treatment = "Post")
# Calculate the synthetic difference-in-differences estimate
current_tau_hat <- synthdid_estimate(current_sDiD$Y, current_sDiD$N0, current_sDiD$T0)
se <- sqrt(vcov(current_tau_hat, method = 'placebo'))
# can increase replications by doing the following: se <- sqrt(vcov(current_tau_hat, method = 'placebo', replications=500))
#default is 200.
# Calculate the t-statistic, null hypothesis is zero
t_statistic <- (as.numeric(current_tau_hat)-0) / se
# Calculate the p-value
p_value_two_tail <- 2 * pt(-abs(t_statistic), df = nrow(current_df) - 1)
p_value_left_tail <-pt(t_statistic, df = nrow(current_df) - 1)
p_value_right_tail <-pt(t_statistic, df = nrow(current_df) - 1, lower.tail = FALSE)
# Print the point estimate, confidence interval, t-statistic, and p-value
cat(sprintf('State: %s\n', state_name))
cat(sprintf('Effective Year: %d\n', current_year))
cat(sprintf('Point estimate: %1.2f\n', current_tau_hat))
cat(sprintf('95%% CI (%1.2f, %1.2f)\n', current_tau_hat - 1.96 * se, current_tau_hat + 1.96 * se))
cat(sprintf('t-statistic: %1.3f\n', t_statistic))
cat(sprintf('p-value: %1.4f\n', p_value_two_tail))
cat(sprintf('p-value-"left-tail": %1.4f\n', p_value_left_tail))
cat(sprintf('p-value-"right-tail": %1.4f\n', p_value_right_tail))
# Summary statistics
#  print(summary(current_tau_hat))
}
print(dim(current_sDiD$Y))
print(dim(current_sDiD$N0))
print(dim(current_sDiD$T0))
print(current_sDiD)
current_df
View(current_df)
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
current_year <- current_df$year_effective[1]
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
View(filt_Corp)
colnames(current_df)
current_df <- current_df[, !grepl("^\\s*$", colnames(current_df))]
# Initialize an empty list to store point estimates and statistics
point_estimate_list <- list()
# Loop over each dataframe in result_list
for (state_name in names(result_list)) {
# Access the dataframe
current_df <- result_list[[state_name]]
#Make the tibble from the result list a dataframe, easier for panel.matrics function
current_df <- as.data.frame(current_df)
current_year <- current_df$year_effective[1]
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
# Filter out those states from the dataframe
current_df <- current_df %>%
filter(!State_Acronym %in% states_with_inf)
# Create the panel matrices for sDiD using synthdid
current_sDiD <- panel.matrices(current_df, unit = "State_Acronym", time = "year", outcome = "per_chan_rci", treatment = "Post")
# Calculate the synthetic difference-in-differences estimate
current_tau_hat <- synthdid_estimate(current_sDiD$Y, current_sDiD$N0, current_sDiD$T0)
se <- sqrt(vcov(current_tau_hat, method = 'placebo'))
# can increase replications by doing the following: se <- sqrt(vcov(current_tau_hat, method = 'placebo', replications=500))
#default is 200.
# Calculate the t-statistic, null hypothesis is zero
t_statistic <- (as.numeric(current_tau_hat)-0) / se
# Calculate the p-value
p_value_two_tail <- 2 * pt(-abs(t_statistic), df = nrow(current_df) - 1)
p_value_left_tail <-pt(t_statistic, df = nrow(current_df) - 1)
p_value_right_tail <-pt(t_statistic, df = nrow(current_df) - 1, lower.tail = FALSE)
# Print the point estimate, confidence interval, t-statistic, and p-value
cat(sprintf('State: %s\n', state_name))
cat(sprintf('Effective Year: %d\n', current_year))
cat(sprintf('Point estimate: %1.2f\n', current_tau_hat))
cat(sprintf('95%% CI (%1.2f, %1.2f)\n', current_tau_hat - 1.96 * se, current_tau_hat + 1.96 * se))
cat(sprintf('t-statistic: %1.3f\n', t_statistic))
cat(sprintf('p-value: %1.4f\n', p_value_two_tail))
cat(sprintf('p-value-"left-tail": %1.4f\n', p_value_left_tail))
cat(sprintf('p-value-"right-tail": %1.4f\n', p_value_right_tail))
# Summary statistics
#  print(summary(current_tau_hat))
}
#Load Packages
library(tidyr)
library(dplyr)
library(tidyverse)
library(lmtest)
library(ggplot2)
library(did) # for running DiD
library(plm)
library(lmtest)
library(synthdid)
library(fixest)
library(boot)
library(ggthemes)
# set seed
set.seed(26)
#JMP Directory
setwd("~/Documents/GitHub/ST-Apportionment/job_market_data")
# Initialize an empty list to store point estimates and statistics
point_estimate_list <- list()
# Loop over each dataframe in result_list
for (state_name in names(result_list)) {
# Access the dataframe
current_df <- result_list[[state_name]]
#Make the tibble from the result list a dataframe, easier for panel.matrics function
current_df <- as.data.frame(current_df)
current_year <- current_df$year_effective[1]
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
# Filter out those states from the dataframe
current_df <- current_df %>%
filter(!State_Acronym %in% states_with_inf)
# Create the panel matrices for sDiD using synthdid
current_sDiD <- panel.matrices(current_df, unit = "State_Acronym", time = "year", outcome = "per_chan_rci", treatment = "Post")
# Calculate the synthetic difference-in-differences estimate
current_tau_hat <- synthdid_estimate(current_sDiD$Y, current_sDiD$N0, current_sDiD$T0)
se <- sqrt(vcov(current_tau_hat, method = 'placebo'))
# can increase replications by doing the following: se <- sqrt(vcov(current_tau_hat, method = 'placebo', replications=500))
#default is 200.
# Calculate the t-statistic, null hypothesis is zero
t_statistic <- (as.numeric(current_tau_hat)-0) / se
# Calculate the p-value
p_value_two_tail <- 2 * pt(-abs(t_statistic), df = nrow(current_df) - 1)
p_value_left_tail <-pt(t_statistic, df = nrow(current_df) - 1)
p_value_right_tail <-pt(t_statistic, df = nrow(current_df) - 1, lower.tail = FALSE)
# Print the point estimate, confidence interval, t-statistic, and p-value
cat(sprintf('State: %s\n', state_name))
cat(sprintf('Effective Year: %d\n', current_year))
cat(sprintf('Point estimate: %1.2f\n', current_tau_hat))
cat(sprintf('95%% CI (%1.2f, %1.2f)\n', current_tau_hat - 1.96 * se, current_tau_hat + 1.96 * se))
cat(sprintf('t-statistic: %1.3f\n', t_statistic))
cat(sprintf('p-value: %1.4f\n', p_value_two_tail))
cat(sprintf('p-value-"left-tail": %1.4f\n', p_value_left_tail))
cat(sprintf('p-value-"right-tail": %1.4f\n', p_value_right_tail))
# Summary statistics
#  print(summary(current_tau_hat))
}
# Create the panel matrices for sDiD using synthdid
current_sDiD <- panel.matrices(current_df, unit = "State_Acronym", time = "year", outcome = "per_chan_rci", treatment = "Post")
# Filter out those states from the dataframe
current_df <- current_df %>%
filter(!State_Acronym %in% states_with_inf)
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
# Access the dataframe
current_df <- result_list[[state_name]]
#Make the tibble from the result list a dataframe, easier for panel.matrics function
current_df <- as.data.frame(current_df)
current_year <- current_df$year_effective[1]
#Drop states that have NA for ratio (like Alaska because no Income Tax)
current_df <- na.omit(current_df[, c("State_Acronym", "year", "per_chan_rci", "Post")])
#eliminate Inf lines and the state that has them for estimation, like Ohio 2009-2013
states_with_inf <- current_df %>%
group_by(State_Acronym) %>%
filter(any(is.infinite(per_chan_rci))) %>%
pull(State_Acronym) %>%
unique()
# Filter out those states from the dataframe
current_df <- current_df %>%
filter(!State_Acronym %in% states_with_inf)
# Create the panel matrices for sDiD using synthdid
current_sDiD <- panel.matrices(current_df, unit = "State_Acronym", time = "year", outcome = "per_chan_rci", treatment = "Post")
# Calculate the synthetic difference-in-differences estimate
current_tau_hat <- synthdid_estimate(current_sDiD$Y, current_sDiD$N0, current_sDiD$T0)
dim(current_sDiD$Y)
current_sDiD$N0
current_sDiD$T0
ncol(current_sDiD$Y)
# Calculate the synthetic difference-in-differences estimate
current_tau_hat <- synthdid_estimate(current_sDiD$Y, current_sDiD$N0, current_sDiD$T0)
se <- sqrt(vcov(current_tau_hat, method = 'placebo'))
# Calculate the t-statistic, null hypothesis is zero
t_statistic <- (as.numeric(current_tau_hat)-0) / se
# Calculate the p-value
p_value_two_tail <- 2 * pt(-abs(t_statistic), df = nrow(current_df) - 1)
p_value_left_tail <-pt(t_statistic, df = nrow(current_df) - 1)
write.csv(per_chan_real_ci,"Percent_Change_real_CI.csv",row.names = FALSE)
