#Attempt to Get Revenue in R
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("did")
install.packages("tidyverse")
install.packages("lmtest")
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
Census State and Local Data- Tax Foundation
# Census State and Local Data- Tax Foundation
install.packages("readxl")
install.packages("tidyr")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("xlsx")
library(readxl)
library(tidyr)
library(dplyr)
library(tidyverse)
library(xlsx)
#Nebraska or "Direct Switchers DiD Approach"
#Run DiD with all the Direct Switchers (NE, MO, MS, CO, RI, ND, DE)
#Control Group is all States that Did not Switch by 2007.
#this includes: AK, HI, KS, NM, OK.  AL and MT between 2008-now became "Step
#-wise" switchers.  FL and MA had DWS over the whole period 1976-2022.
library(tidyr)
library(dplyr)
library(tidyverse)
# for robust standard error estimation
library(lmtest)
# To calculate correct vcov matrix with 2WFE
library(multiwayvcov)
# For a package way to do FE
library(plm)
#Fixest
install.packages("fixest")
library(fixest)
#Load Data Tables in R
install.packages("data.table")
# Get rate of change for tax bases and find elasticity of tax base w.r.t apportionment and rate changes.
#Redo Callaway and Sant'Anna From Summer
library(readxl)
library(tidyr)
library(dplyr)
library(did)
library(tidyverse)
library(lmtest)
library(caret)
library(ggplot2)
#New Directory
setwd("~/Documents/GitHub/ST_Apportionment/Rates_Of_Change")
library(tidyr)
library(dplyr)
library(tidyverse)
library(lmtest)
library(ggplot2)
library(readxl) #load ssfa switch date
library(did) # for running DiD
library(caret)
library(plm) # for Two way FE
library(fixest) # multiple FE
library(broom) #extract coefficients for each state
set.seed(26)
setwd("~/Documents/GitHub/ST-Apportionment/job_market_data")
Rev <- read.csv("filled_data_jmp.csv")
View(Rev)
#More modifications, might not have all states
Rev2 <- read.csv("detrend_per_capita.csv")
Log_rev <- read.csv("filled_log_data_jmp.csv")
Date <- read_xlsx("ssfa_data_jmp.xlsx")
View(Date)
View(Date)
SSFA <- read_xlsx("ssfa_data_jmp.xlsx")
View(Rev)
View(Rev2)
View(Rev2)
View(Rev2)
View(Rev)
View(Rev2)
View(Log_rev)
#Need to merge back our Non CIT states and their data
NoCIT <- read.csv("Non_CIT_states_FRED_OH.csv")
View(NoCIT)
Merge <- NoCIT %>%
bind_rows(Rev2)
View(Merge)
Merge2 <- NoCIT %>%
bind_rows(Rev)
View(Merge2)
View(Merge2)
str(Merge2)
#Load rates dataframe
Rates<- read.csv("elasticity_rates_jmp.csv")
#Load rates dataframe
Rates<- read.csv("clean_rates_1976-2022.csv")
View(Rates)
Rates2 <- read.csv("rates_jmp.csv")
View(Rates2)
#Now, need to just bet back to the original FRED Revenues alone
Orig <- Merge2 %>%
select(-X,-industry_dum,-election_dum,-phase_in_dum,-rates,-Number)
View(Orig)
View(Orig)
str(Orig)
Sev <- Orig %>%
select(State_Acronym,year,SVRNCTAX,state,sales,Region)
View(SSFA)
State_Acronym <- c("AK", "AL", "AR", "AZ", "CA", "CO", "CT", "DE", "FL", "GA",
"HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA", "MA", "MD",
"ME", "MI", "MN", "MO", "MS", "MT", "NC", "ND", "NE", "NH",
"NJ", "NM", "NV", "NY", "OH", "OK", "OR", "PA", "RI", "SC",
"SD", "TN", "TX", "UT", "VA", "VT", "WA", "WI", "WV", "WY")
state <- c("Alaska", "Alabama", "Arkansas", "Arizona", "California", "Colorado",
"Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Iowa",
"Idaho", "Illinois", "Indiana", "Kansas", "Kentucky", "Louisiana",
"Massachusetts", "Maryland", "Maine", "Michigan", "Minnesota",
"Missouri", "Mississippi", "Montana", "North Carolina", "North Dakota",
"Nebraska", "New Hampshire", "New Jersey", "New Mexico", "Nevada",
"New York", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island",
"South Carolina", "South Dakota", "Tennessee", "Texas", "Utah",
"Virginia", "Vermont", "Washington", "Wisconsin", "West Virginia",
"Wyoming")
state_data <- data.frame(State_Acronym, state)
print(state_data)
#Merge with Orig
Orig2 <- Orig %>%
left_join(state_data,by=c("State_Acronym"))
View(Orig2)
rename(state.y=state)
rename(Orig2$state.y=Orig2$state)
rename(state=state.y)
select(-state.x)
left_join(state_data,by=c("State_Acronym")
left_join(state_data,by=c("State_Acronym")
#Merge with Orig
Orig2 <- Orig %>%
left_join(state_data,by=c("State_Acronym"))
Orig3 <- Orig2 %>%
select(-state.x)%>%
rename(state=state.y)
View(Orig3)
write.csv(Orig3,"FRED_rev_all_states.csv")
#Severance Data
Sev <- Orig %>%
select(State_Acronym,year,SVRNCTAX,state,sales)
View(Sev)
#Severance Data
Sev <- Orig3 %>%
select(State_Acronym,year,SVRNCTAX,state,sales)
View(Sev)
View(SSFA)
SSFA2 <- SSFA %>%
select(state,year_effective)
Sev2 %>% Sev %>%
full_join(SSFA2, by= c("state"))
Sev2 <- Sev %>%
full_join(SSFA2, by= c("state"))
View(Sev2)
View(Rev2)
# Create a Post Column, for year effective.
Sev3 <- Sev2 %>%
group_by(state) %>%
mutate(post_eff = ifelse(year_effective > year, 0, 1)) %>%
ungroup()
#Create a Relative Year column for the Event Study Plot
# Create rel_year column
Sev3$rel_year <- Sev3$year - Sev3$year_effective
View(Sev3)
write.csv(Sev3,"Severance_2WFE.csv")
Sev <-read.csv("Severance_2WFE.csv")
write.csv(Sev3,"Severance_2WFE.csv",row.names=FALSE)
Sev <-read.csv("Severance_2WFE.csv")
View(Sev)
Sev <-read.csv("Severance_2WFE.csv")
#Merge with population data
pop <- read.csv("rev_population.csv")
View(pop)
#Load Files
Pop <-read_excel("State_Resident_Population2.xls",sheet=1)
#Load Files
Pop <-read_excel("Documents/SALT Directory/MyContent_stlouisfed/State_Resident_Population2.xls",sheet=1)
#Merge with population data
library(xlsx)
library(xlsx)
library(readxl)
#Load Files
Pop <-read_excel("State_Resident_Population2.xls",sheet=1)
#Load Files
Pop <-read_excel("State_Resident_Population.xls",sheet=1)
View(Pop)
#Load Files
Pop <-read_excel("State_Resident_Population.xls",sheet=2)
View(Pop)
#Clean Up Year for Pop
library(lubridate)
